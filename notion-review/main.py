# -*- coding: utf-8 -*-
"""
Notion æ™ºèƒ½ä»»åŠ¡ä¸å¤ç›˜ç³»ç»Ÿ v8 (Final)
åŠŸèƒ½æ¦‚è§ˆ:
 - æ¯æ—¥ 00:00: è‡ªåŠ¨é¡ºå»¶æœªå®Œæˆä»»åŠ¡ -> æŠŠæ¥æºæ—¥æœŸæ”¹ä¸ºä»Šæ—¥
 - æ¯æ—¥ 23:55: åˆ›å»º/æ›´æ–°æ¯æ—¥å¤ç›˜å­é¡µé¢ï¼ˆä¿ç•™æ‰‹åŠ¨å¡«å†™å†…å®¹ï¼‰
 - æ¯å‘¨ï¼ˆå‘¨æ—¥ 23:55ï¼‰: è‡ªåŠ¨ç”Ÿæˆæ¯å‘¨å¤ç›˜ï¼ˆä»æ¯æ—¥å¤ç›˜æ±‡æ€»ï¼‰
 - æ¯æœˆï¼ˆå½“æœˆæœ€åä¸€å¤© 23:55ï¼‰: è‡ªåŠ¨ç”Ÿæˆæ¯æœˆå¤ç›˜
 - å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹å¹¶è¡¥é½æ•°æ®åº“å­—æ®µ
 - system_check() æ¯æ¬¡è¿è¡Œå‰åšå¥åº·æ£€æŸ¥
 - config.json ç®¡ç†é…ç½®ï¼Œä¸æŠŠ token ç¡¬ç¼–ç åœ¨è„šæœ¬ä¸­
"""

import os
import sys
import json
import traceback
import requests
import subprocess
from datetime import datetime, timedelta
from collections import Counter
import pytz

# ---------------- auto-install minimal package ----------------
def ensure_pkg(pkg):
    try:
        __import__(pkg)
    except ImportError:
        print(f"âš™ï¸ æœªæ£€æµ‹åˆ°æ¨¡å— {pkg}ï¼Œè‡ªåŠ¨å®‰è£…ä¸­...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])

ensure_pkg("schedule")
import schedule
# ----------------------------------------------------------------

# ---------------- load config.json ----------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "config.json")

if not os.path.exists(CONFIG_PATH):
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ° config.jsonï¼Œè¯·å‚è€ƒ README åˆ›å»ºå¹¶å¡«å†™ NOTION_TOKEN ä¸æ•°æ®åº“ IDã€‚")

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    cfg = json.load(f)

NOTION_TOKEN = cfg.get("NOTION_TOKEN")
TASK_DB_ID = cfg.get("TASK_DATABASE_ID")             # ä»»åŠ¡æ•°æ®åº“
DAILY_REVIEW_DB_ID = cfg.get("REVIEW_DAILY_DB_ID")  # æ¯æ—¥å¤ç›˜æ•°æ®åº“ï¼ˆå­é¡µé¢åº“ï¼‰
CYCLE_REVIEW_DB_ID = cfg.get("REVIEW_CYCLE_DB_ID")  # å‘¨/æœˆå¤ç›˜æ•°æ®åº“ï¼ˆå¯ä¸ DAILY åŒåº“ï¼Œä¹Ÿå¯åˆ†å¼€ï¼‰
OPENAI_API_KEY = cfg.get("OPENAI_API_KEY")          # å¯é€‰ï¼Œè‹¥å¯ç”¨ AI æ€»ç»“
OPENAI_MODEL = cfg.get("OPENAI_MODEL", "gpt-4o-mini")

if not NOTION_TOKEN or not TASK_DB_ID:
    raise SystemExit("è¯·åœ¨ config.json ä¸­è®¾ç½® NOTION_TOKEN ä¸ TASK_DATABASE_ID å¹¶é‡å¯è„šæœ¬ã€‚")

HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Notion-Version": "2022-06-28",
    "Content-Type": "application/json"
}

tz = pytz.timezone(cfg.get("TZ", "Asia/Shanghai"))
now = datetime.now(tz)
TODAY = now.strftime("%Y-%m-%d")

# ---------------- logging util ----------------
def log(msg):
    print(f"[{datetime.now(tz).isoformat()}] {msg}")

# ---------------- Notion helpers ----------------
def notion_get(url):
    r = requests.get(url, headers=HEADERS)
    return r

def notion_post(url, payload):
    r = requests.post(url, headers=HEADERS, json=payload)
    return r

def notion_patch(url, payload):
    r = requests.patch(url, headers=HEADERS, json=payload)
    return r

# ---------------- DB schema helpers ----------------
def get_database_info(dbid):
    r = notion_get(f"https://api.notion.com/v1/databases/{dbid}")
    if r.status_code != 200:
        log(f"ERROR: get_database_info {dbid} -> {r.status_code} {r.text}")
        return None
    return r.json()

def ensure_props_on_db(dbid, required_props):
    """
    required_props: dict: { "å­—æ®µå": property_schema }
    property_schema is in Notion API format, e.g. {"number":{}} or {"title":{}}
    """
    info = get_database_info(dbid)
    if not info:
        return False
    existing = set(info.get("properties", {}).keys())
    to_add = {k:v for k,v in required_props.items() if k not in existing}
    if not to_add:
        log(f"âœ… æ•°æ®åº“ {dbid} å·²åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µã€‚")
        return True
    payload = {"properties": to_add}
    r = notion_patch(f"https://api.notion.com/v1/databases/{dbid}", payload)
    if r.status_code in (200,201):
        log(f"âš™ï¸ å·²è‡ªåŠ¨è¡¥é½æ•°æ®åº“ {dbid} å­—æ®µï¼š{', '.join(to_add.keys())}")
        return True
    else:
        log(f"âŒ è¡¥é½æ•°æ®åº“å­—æ®µå¤±è´¥ï¼š{r.status_code} {r.text}")
        return False

# ---------------- match task DB column names (å®¹é”™åŒ¹é…) ----------------
def match_task_columns(dbinfo):
    props = dbinfo.get("properties", {})
    cols = {}
    for name, meta in props.items():
        t = meta.get("type")
        lname = name.lower()
        if t == "title" and "title" not in cols:
            cols["title"] = name
        if t == "date" and ("æ¥æº" in name or "æ¥æº" in lname or "date" in lname or "æ—¥" in name):
            cols["source_date"] = name
        if t == "date" and "date" not in cols:
            cols["date"] = name
        if t == "select" and ("çŠ¶" in name or "çŠ¶æ€" in name or "status" in lname):
            cols["status"] = name
        if t == "url" and "resource" not in cols:
            cols["resource"] = name
        if t == "number" and ("æ—¶" in name or "æ—¶é•¿" in name or "duration" in lname):
            cols["duration"] = name
        if t == "rich_text" and ("æ" in name or "æç¤º" in name or "hint" in lname):
            cols["hint"] = name
    # fallback
    for name, meta in props.items():
        if meta.get("type") == "title" and "title" not in cols:
            cols["title"] = name
        if meta.get("type") == "date" and "date" not in cols:
            cols["date"] = name
        if meta.get("type") == "select" and "status" not in cols:
            cols["status"] = name
    log(f"Matched task DB columns: {cols}")
    return cols

# ---------------- query helpers ----------------
def query_database_by_date(dbid, date_prop_name, date_str):
    payload = {"filter": {"property": date_prop_name, "date": {"equals": date_str}}}
    r = notion_post(f"https://api.notion.com/v1/databases/{dbid}/query", payload)
    if r.status_code != 200:
        log(f"ERROR query_database_by_date {dbid}: {r.status_code} {r.text}")
        return []
    return r.json().get("results", [])

# ---------------- rollover (æœªå®Œæˆä»»åŠ¡é¡ºå»¶) ----------------
def rollover_unfinished_tasks():
    # get task DB info and match columns
    dbinfo = get_database_info(TASK_DB_ID)
    if not dbinfo:
        log("ERROR: æ— æ³•è¯»å–ä»»åŠ¡æ•°æ®åº“ä¿¡æ¯")
        return
    cols = match_task_columns(dbinfo)
    if not cols.get("date") or not cols.get("status") or not cols.get("title"):
        log("ERROR: ä»»åŠ¡æ•°æ®åº“å¿…é¡»åŒ…å« date/title/status åˆ—")
        return

    yesterday = (datetime.now(tz) - timedelta(days=1)).strftime("%Y-%m-%d")
    yesterday_tasks = query_database_by_date(TASK_DB_ID, cols["date"], yesterday)
    log(f"æ£€æµ‹åˆ°æ˜¨æ—¥ä»»åŠ¡ {len(yesterday_tasks)} æ¡ï¼Œå¼€å§‹æ£€æµ‹æœªå®Œæˆå¹¶é¡ºå»¶...")
    rolled = []
    for p in yesterday_tasks:
        props = p.get("properties", {})
        status_sel = props.get(cols["status"], {}).get("select")
        title = ""
        title_field = props.get(cols["title"], {})
        if title_field.get("title"):
            title = title_field["title"][0].get("plain_text","")
        if not status_sel or status_sel.get("name") not in ("å·²å®Œæˆ","å®Œæˆ","Done","done"):
            # create a new page for today copying title and other useful props
            new_props = {}
            # copy title
            new_props[cols["title"]] = {"title":[{"text":{"content": title}}]}
            # set date -> today (use same date prop name)
            new_props[cols["date"]] = {"date":{"start": datetime.now(tz).strftime("%Y-%m-%d")}}
            # reset status to æœªå¼€å§‹
            if cols.get("status"):
                new_props[cols["status"]] = {"select":{"name":"æœªå¼€å§‹"}}
            # copy resource if exists
            if cols.get("resource"):
                url_val = props.get(cols["resource"], {}).get("url")
                if url_val:
                    new_props[cols["resource"]] = {"url": url_val}
            # try to copy hint
            if cols.get("hint"):
                rt = props.get(cols["hint"], {}).get("rich_text", [])
                if rt:
                    new_props[cols["hint"]] = {"rich_text": rt}
            # create
            payload = {"parent":{"database_id": TASK_DB_ID}, "properties": new_props}
            r = notion_post("https://api.notion.com/v1/pages", payload)
            if r.status_code in (200,201):
                rolled.append(title)
            else:
                log(f"âš  æ— æ³•é¡ºå»¶ä»»åŠ¡ â€œ{title}â€ï¼š{r.status_code} {r.text}")
    if rolled:
        log(f"â†©ï¸ å·²é¡ºå»¶ {len(rolled)} ä¸ªä»»åŠ¡åˆ°ä»Šæ—¥ï¼š{rolled}")
    else:
        log("âœ… æ— éœ€é¡ºå»¶æˆ–é¡ºå»¶æ— å¤±è´¥é¡¹ã€‚")

# ---------------- create / update daily review ----------------
def find_review_entry_by_date(review_db_id, date_str):
    payload = {"filter": {"property":"ğŸ“… æ—¥æœŸ", "date":{"equals": date_str}}}
    r = notion_post(f"https://api.notion.com/v1/databases/{review_db_id}/query", payload)
    if r.status_code != 200:
        log(f"ERROR find_review_entry_by_date: {r.status_code} {r.text}")
        return None
    results = r.json().get("results", [])
    return results[0] if results else None

def create_daily_review_if_missing(review_db_id):
    # compute today's task stats
    dbinfo = get_database_info(TASK_DB_ID)
    cols = match_task_columns(dbinfo)
    if not cols.get("date") or not cols.get("status"):
        log("ERROR: ä»»åŠ¡æ•°æ®åº“ç¼ºå¤± date æˆ– status åˆ—ï¼Œæ— æ³•ç»Ÿè®¡ä»Šæ—¥ä»»åŠ¡")
        return False
    total, done = 0, 0
    tasks = query_database_by_date(TASK_DB_ID, cols["date"], TODAY)
    total = len(tasks)
    for t in tasks:
        sel = t["properties"].get(cols["status"], {}).get("select")
        if sel and sel.get("name") in ("å·²å®Œæˆ","å®Œæˆ","Done","done"):
            done += 1
    undone = total - done

    existing = find_review_entry_by_date(review_db_id, TODAY)
    if existing:
        # update counts but preserve rich_text fields (do not overwrite)
        page_id = existing["id"]
        update_payload = {}
        # if properties contain these names, update them
        update_payload["âœ… å®Œæˆä»»åŠ¡æ•°"] = {"number": done}
        update_payload["âŒ æœªå®Œæˆä»»åŠ¡æ•°"] = {"number": undone}
        r = notion_patch(f"https://api.notion.com/v1/pages/{page_id}", {"properties": update_payload})
        if r.status_code in (200,201):
            log(f"âœ… æ›´æ–°ä»Šæ—¥å¤ç›˜æ•°æ®ï¼šå®Œæˆ {done} / æ€» {total}")
            return True
        else:
            log(f"âš  æ›´æ–°ä»Šæ—¥å¤ç›˜å¤±è´¥ï¼š{r.status_code} {r.text}")
            return False
    else:
        # create new daily review page
        props = {
            "åç§°": { "title": [ { "text": {"content": title_text} } ] },
            "æ—¥æœŸ": { "date": {"start": today} },
            "âœ… å®Œæˆä»»åŠ¡æ•°": {"number": done},
            "âŒ æœªå®Œæˆä»»åŠ¡æ•°": {"number": undone},
    "ğŸª æ€»ç»“": {
        "rich_text": [
            {"text": {"content": "ï¼ˆè¯·è¡¥å……æ¯æ—¥å¤ç›˜ï¼‰"}}
        ]
    },
    "âš  éš¾ç‚¹": {
        "rich_text": [
            {"text": {"content": "ï¼ˆè¯·è®°å½•ä»Šæ—¥éš¾ç‚¹ï¼‰"}}
        ]
    },
    "ğŸ’¡ è§£å†³æ–¹æ¡ˆ": {
        "rich_text": [
            {"text": {"content": "ï¼ˆè¯·å¡«å†™è§£å†³æ–¹æ¡ˆï¼‰"}}
        ]
    },
    "ğŸ§© ç±»å‹": {
        "select": {"name": "æ¯æ—¥å¤ç›˜"}
    }
}
        r = notion_post("https://api.notion.com/v1/pages", {"parent":{"database_id": review_db_id}, "properties": props})
        if r.status_code in (200,201):
            log(f"ğŸ†• åˆ›å»ºä»Šæ—¥å¤ç›˜é¡µé¢ï¼š{TODAY}ï¼ˆå®Œæˆ {done} / {total}ï¼‰")
            return True
        else:
            log(f"âŒ åˆ›å»ºä»Šæ—¥å¤ç›˜å¤±è´¥ï¼š{r.status_code} {r.text}")
            return False

# ---------------- collect daily reviews for a date range ----------------
def collect_daily_reviews(review_db_id, start_date, end_date):
    payload = {
        "filter": {
            "and": [
                {"property":"ğŸ“… æ—¥æœŸ", "date":{"on_or_after": start_date}},
                {"property":"ğŸ“… æ—¥æœŸ", "date":{"on_or_before": end_date}}
            ]
        },
        "page_size": 100
    }
    r = notion_post(f"https://api.notion.com/v1/databases/{review_db_id}/query", payload)
    if r.status_code != 200:
        log(f"ERROR collect_daily_reviews: {r.status_code} {r.text}")
        return []
    items = r.json().get("results", [])
    # ensure they are of ç±»å‹ "æ¯æ—¥" or empty
    filtered = []
    for it in items:
        t = it["properties"].get("ç±»å‹", {}).get("select", {}).get("name","")
        if t in ("æ¯æ—¥",""):
            filtered.append(it)
    return filtered

# ---------------- summarize keywords from reviews ----------------
def summarize_keywords(items, field_name="âš  éš¾ç‚¹", top_n=5):
    words = []
    for it in items:
        rt = it["properties"].get(field_name, {}).get("rich_text", [])
        text = "".join([x.get("plain_text","") for x in rt]) if rt else ""
        # basic splitting
        tokens = [w.strip() for w in text.replace("ã€"," ").replace(","," ").split() if w.strip()]
        words.extend(tokens)
    cnt = Counter(words)
    return cnt.most_common(top_n)

# ---------------- AI summary (optional) ----------------
def generate_ai_summary(prompt, model=OPENAI_MODEL):
    if not OPENAI_API_KEY:
        log("WARN: OPENAI_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ AI æ€»ç»“")
        return "ï¼ˆAI æœªå¯ç”¨ï¼‰"
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type":"application/json"}
    payload = {
        "model": model,
        "messages": [{"role":"system","content":"ä½ æ˜¯ä¸€ä½æ‰§è¡Œæ•™ç»ƒï¼Œå¸®åŠ©æ€»ç»“å…³é”®ç»“è®ºä¸æ”¹è¿›å»ºè®®ã€‚"},
                     {"role":"user","content":prompt}],
        "temperature": 0.2,
        "max_tokens": 600
    }
    r = requests.post(url, headers=headers, json=payload)
    if r.status_code == 200:
        try:
            txt = r.json()["choices"][0]["message"]["content"].strip()
            return txt
        except Exception as e:
            log("AI parse error: " + str(e))
            return "ï¼ˆAI è¿”å›è§£æå¤±è´¥ï¼‰"
    else:
        log(f"AI è¯·æ±‚å¤±è´¥ï¼š{r.status_code} {r.text}")
        return "ï¼ˆAI è¯·æ±‚å¤±è´¥ï¼‰"

# ---------------- create periodic review (weekly/monthly) ----------------
def create_periodic_review(review_db_id, start_date, end_date, kind="æ¯å‘¨"):
    items = collect_daily_reviews(review_db_id, start_date, end_date)
    total_tasks = sum(int(it["properties"].get("âœ… å®Œæˆä»»åŠ¡æ•°", {}).get("number") or 0) +
                      int(it["properties"].get("âŒ æœªå®Œæˆä»»åŠ¡æ•°", {}).get("number") or 0)
                      for it in items)
    total_done = sum(int(it["properties"].get("âœ… å®Œæˆä»»åŠ¡æ•°", {}).get("number") or 0) for it in items)
    avg_done = round((total_done / len(items)) if items else 0, 2)
    top = summarize_keywords(items)
    top_str = "; ".join([f"{k}({v}æ¬¡)" for k,v in top]) if top else "æ— æ˜æ˜¾é«˜é¢‘éš¾ç‚¹"

    prompt = f"""è¯·ä¸ºç”¨æˆ·ç”Ÿæˆä¸€ä»½{kind}æ€»ç»“ï¼š
æ—¶é—´èŒƒå›´ï¼š{start_date} åˆ° {end_date}
å…±è®¡å¤©æ•°ï¼š{len(items)}ï¼Œå®Œæˆä»»åŠ¡æ€»æ•°ï¼š{total_done}ï¼Œæ€»ä»»åŠ¡æ•°ï¼š{total_tasks}ï¼Œå¹³å‡æ¯æ—¥å®Œæˆï¼š{avg_done}
é«˜é¢‘éš¾ç‚¹ï¼š{top_str}
è¯·è¾“å‡ºï¼š1) å…³é”®ç»“è®º 2) æ”¹è¿›å»ºè®® 3) ä¸€æ®µ 1-2 æ®µè½çš„æ€»ç»“è¯­ã€‚"""
    ai_text = generate_ai_summary(prompt)

    props = {
        "ğŸ“ æ ‡é¢˜": {"title":[{"text":{"content": f"{kind} å¤ç›˜ {end_date}"}}]},
        "ğŸ“… æ—¥æœŸ": {"date":{"start": end_date}},
        "âœ… å®Œæˆä»»åŠ¡æ•°": {"number": total_done},
        "âŒ æœªå®Œæˆä»»åŠ¡æ•°": {"number": total_tasks - total_done},
        "âš  éš¾ç‚¹": {"rich_text":[{"text":{"content": top_str}}]},
        "ğŸ’¡ è§£å†³æ–¹æ¡ˆ": {"rich_text":[{"text":{"content": "ï¼ˆè‡ªåŠ¨æ±‡æ€»ï¼‰\n" + ai_text}}]},
        "æ€»ç»“": {"rich_text":[{"text":{"content": ai_text}}]},
        "ç±»å‹": {"select":{"name": "æ¯å‘¨" if kind=="æ¯å‘¨" else "æ¯æœˆ"}}
    }
    r = notion_post("https://api.notion.com/v1/pages", {"parent": {"database_id": review_db_id}, "properties": props})
    if r.status_code in (200,201):
        log(f"âœ… å·²åˆ›å»º {kind} å¤ç›˜ï¼š{end_date}")
    else:
        log(f"âŒ åˆ›å»º {kind} å¤ç›˜å¤±è´¥ï¼š{r.status_code} {r.text}")

# ---------------- system_check ----------------
def system_check():
    try:
        log("ğŸ§  ç³»ç»Ÿè‡ªæ£€å¼€å§‹...")
        # 1) æ˜¨æ—¥æœªå®Œæˆä»»åŠ¡æ˜¯å¦å·²é¡ºå»¶åˆ°ä»Šæ—¥
        yesterday = (datetime.now(tz) - timedelta(days=1)).strftime("%Y-%m-%d")
        dbinfo = get_database_info(TASK_DB_ID)
        if not dbinfo:
            log("âŒ æ— æ³•è¯»å– Task DB")
            return
        cols = match_task_columns(dbinfo)
        if not cols.get("date") or not cols.get("status") or not cols.get("title"):
            log("âŒ Task DB åˆ—åŒ¹é…å¤±è´¥ï¼ˆéœ€è¦ date/title/statusï¼‰")
            return
        y_tasks = query_database_by_date(TASK_DB_ID, cols["date"], yesterday)
        unfinished = []
        for t in y_tasks:
            sel = t["properties"].get(cols["status"], {}).get("select")
            title = t["properties"].get(cols["title"], {}).get("title",[{}])[0].get("plain_text","")
            if not sel or sel.get("name") not in ("å·²å®Œæˆ","å®Œæˆ","Done","done"):
                unfinished.append(title)
        if unfinished:
            log(f"âš  æ˜¨æ—¥æœªå®Œæˆä»»åŠ¡ï¼ˆ{len(unfinished)}ï¼‰ï¼š{unfinished}")
            # check if present today
            today_tasks = query_database_by_date(TASK_DB_ID, cols["date"], TODAY)
            today_titles = [tt["properties"].get(cols["title"], {}).get("title",[{}])[0].get("plain_text","") for tt in today_tasks]
            not_roll = [x for x in unfinished if x not in today_titles]
            if not_roll:
                log(f"âŒ ä»¥ä¸‹ä»»åŠ¡æœªé¡ºå»¶åˆ°ä»Šæ—¥ï¼š{not_roll}")
            else:
                log("âœ… æ‰€æœ‰æœªå®Œæˆä»»åŠ¡å·²é¡ºå»¶åˆ°ä»Šæ—¥")
        else:
            log("âœ… æ˜¨æ—¥å…¨éƒ¨ä»»åŠ¡å·²å®Œæˆ")

        # 2) ä»Šæ—¥å¤ç›˜æ˜¯å¦å­˜åœ¨
        if not DAILY_REVIEW_DB_ID:
            log("âš  æœªè®¾ç½® DAILY_REVIEW_DB_IDï¼ˆæ¯æ—¥å¤ç›˜æ•°æ®åº“ï¼‰ï¼Œæ— æ³•æ£€æŸ¥")
        else:
            rev = find_review_entry_by_date(DAILY_REVIEW_DB_ID, TODAY)
            if rev:
                log("âœ… ä»Šæ—¥å¤ç›˜å·²å­˜åœ¨")
            else:
                log("âš  ä»Šæ—¥å¤ç›˜å°šæœªç”Ÿæˆ")

        # 3) å‘¨/æœˆ æ£€æŸ¥ï¼ˆåªåœ¨å‘¨æ—¥æˆ–æœˆæœ«åšï¼‰
        dnow = datetime.now(tz)
        if dnow.weekday() == 6:
            # check weekly
            log("ğŸ” å½“å‰ä¸ºå‘¨æ—¥ï¼Œæ£€æŸ¥å‘¨å¤ç›˜")
            # we check existence of entry with ç±»å‹ æ¯å‘¨ and date end = today
            if not CYCLE_REVIEW_DB_ID:
                log("âš  æœªè®¾ç½® CYCLE_REVIEW_DB_IDï¼ˆå‘¨/æœˆå¤ç›˜æ•°æ®åº“ï¼‰")
            else:
                payload = {"filter":{"and":[{"property":"ç±»å‹","select":{"equals":"æ¯å‘¨"}},{"property":"ğŸ“… æ—¥æœŸ","date":{"equals":TODAY}}]}}
                r = notion_post(f"https://api.notion.com/v1/databases/{CYCLE_REVIEW_DB_ID}/query", payload)
                if r.status_code == 200 and r.json().get("results"):
                    log("âœ… æœ¬å‘¨å¤ç›˜å·²å­˜åœ¨")
                else:
                    log("âš  æœ¬å‘¨å¤ç›˜å°šæœªç”Ÿæˆ")
        # month end check
        tomorrow = (datetime.now(tz) + timedelta(days=1)).strftime("%Y-%m-%d")
        if datetime.strptime(tomorrow, "%Y-%m-%d").month != datetime.now(tz).month:
            log("ğŸ” ä»Šæ—¥ä¸ºæœˆæœ«ï¼Œæ£€æŸ¥æœˆå¤ç›˜")
            if not CYCLE_REVIEW_DB_ID:
                log("âš  æœªè®¾ç½® CYCLE_REVIEW_DB_IDï¼ˆå‘¨/æœˆå¤ç›˜æ•°æ®åº“ï¼‰")
            else:
                payload = {"filter":{"and":[{"property":"ç±»å‹","select":{"equals":"æ¯æœˆ"}},{"property":"ğŸ“… æ—¥æœŸ","date":{"equals":TODAY}}]}}
                r = notion_post(f"https://api.notion.com/v1/databases/{CYCLE_REVIEW_DB_ID}/query", payload)
                if r.status_code == 200 and r.json().get("results"):
                    log("âœ… æœ¬æœˆå¤ç›˜å·²å­˜åœ¨")
                else:
                    log("âš  æœ¬æœˆå¤ç›˜å°šæœªç”Ÿæˆ")
        log("ğŸ§© ç³»ç»Ÿè‡ªæ£€å®Œæˆ")
    except Exception as e:
        log("âŒ ç³»ç»Ÿè‡ªæ£€å¼‚å¸¸: " + str(e))
        traceback.print_exc()

# ---------------- main flow ----------------
def main_flow():
    log("å¼€å§‹ v8 è‡ªåŠ¨å¤ç›˜ä¸»æµç¨‹")
    # ensure review DB fields exist (if configured)
    daily_required = {
        "ğŸ“ æ ‡é¢˜":{"title":{}},
        "ğŸ“… æ—¥æœŸ":{"date":{}},
        "âœ… å®Œæˆä»»åŠ¡æ•°":{"number":{}},
        "âŒ æœªå®Œæˆä»»åŠ¡æ•°":{"number":{}},
        "âš  éš¾ç‚¹":{"rich_text":{}},
        "ğŸ’¡ è§£å†³æ–¹æ¡ˆ":{"rich_text":{}},
        "æ€»ç»“":{"rich_text":{}},
        "ç±»å‹":{"select":{"options":[{"name":"æ¯æ—¥"},{"name":"æ¯å‘¨"},{"name":"æ¯æœˆ"}]}}
    }
    if DAILY_REVIEW_DB_ID:
        ensure_props_on_db(DAILY_REVIEW_DB_ID, daily_required)
    if CYCLE_REVIEW_DB_ID:
        ensure_props_on_db(CYCLE_REVIEW_DB_ID, daily_required)

    # 1. rollover yesterday unfinished -> today
    rollover_unfinished_tasks()

    # 2. create or update today's daily review
    if DAILY_REVIEW_DB_ID:
        create_daily_review_if_missing(DAILY_REVIEW_DB_ID)
    else:
        log("âš  æœªé…ç½® DAILY_REVIEW_DB_IDï¼Œè·³è¿‡æ¯æ—¥å¤ç›˜å†™å…¥")

    # 3. weekly/monthly periodic creation
    dnow = datetime.now(tz)
    if dnow.weekday() == 6 and CYCLE_REVIEW_DB_ID:
        # weekly: last 7 days
        start = (dnow - timedelta(days=6)).strftime("%Y-%m-%d")
        end = dnow.strftime("%Y-%m-%d")
        create_periodic_review(CYCLE_REVIEW_DB_ID, start, end, kind="æ¯å‘¨")
    # if month end
    tomorrow = (dnow + timedelta(days=1)).strftime("%Y-%m-%d")
    if datetime.strptime(tomorrow, "%Y-%m-%d").month != dnow.month and CYCLE_REVIEW_DB_ID:
        start = dnow.replace(day=1).strftime("%Y-%m-%d")
        end = dnow.strftime("%Y-%m-%d")
        create_periodic_review(CYCLE_REVIEW_DB_ID, start, end, kind="æ¯æœˆ")

    log("ä¸»æµç¨‹å®Œæˆã€‚")

# ---------------- schedule ----------------
def run_scheduler():
    # schedule main_flow at 00:00 (rollover) and 23:55 (daily review + periodic)
    schedule.clear()
    schedule.every().day.at(cfg.get("ROLLOVER_TIME","00:00")).do(lambda: (system_check(), rollover_unfinished_tasks()))
    schedule.every().day.at(cfg.get("DAILY_REVIEW_TIME","23:55")).do(lambda: (system_check(), main_flow()))
    log("è°ƒåº¦å·²è®¾ç½®ï¼šæ¯æ—¥é¡ºå»¶æ—¶é—´ %sï¼Œå¤ç›˜æ—¶é—´ %s" % (cfg.get("ROLLOVER_TIME","00:00"), cfg.get("DAILY_REVIEW_TIME","23:55")))
    # run loop
    while True:
        schedule.run_pending()
        import time
        time.sleep(10)

# ---------------- CLI util for manual run ----------------
def run_now():
    system_check()
    main_flow()

# ---------------- entry ----------------
if __name__ == "__main__":
    log("å¯åŠ¨ Notion æ™ºèƒ½å¤ç›˜ç³»ç»Ÿ v8")
    # quick checks
    try:
        run_now()
    except Exception as e:
        log("ä¸»æµç¨‹å¼‚å¸¸: " + str(e))
        traceback.print_exc()
    # if user wants continuous scheduler, uncomment below:
    if cfg.get("ENABLE_SCHEDULER", False):
        run_scheduler()
        import schedule, time

def job():
    print("â° æ¯æ—¥è‡ªåŠ¨å¤ç›˜å¼€å§‹...")
    main()